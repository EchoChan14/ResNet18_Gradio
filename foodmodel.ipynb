{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f25aa92-8c93-420b-9347-1f97be37e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹å·²æˆåŠŸè¼‰å…¥\n",
      "Epoch 1: Loss=1.1726, Train Acc=0.5800, Val Acc=0.2800\n",
      "Epoch 2: Loss=1.0364, Train Acc=0.6373, Val Acc=0.2840\n",
      "Epoch 3: Loss=0.9902, Train Acc=0.6493, Val Acc=0.2840\n",
      "Epoch 4: Loss=0.9456, Train Acc=0.6787, Val Acc=0.2920\n",
      "Epoch 5: Loss=0.9065, Train Acc=0.6980, Val Acc=0.3000\n",
      "Epoch 6: Loss=0.8650, Train Acc=0.7060, Val Acc=0.2980\n",
      "Epoch 7: Loss=0.8330, Train Acc=0.7240, Val Acc=0.2820\n",
      "Epoch 8: Loss=0.7891, Train Acc=0.7367, Val Acc=0.2760\n",
      "Epoch 9: Loss=0.7183, Train Acc=0.7687, Val Acc=0.2860\n",
      "Epoch 10: Loss=0.6710, Train Acc=0.7987, Val Acc=0.2840\n",
      "âœ… æ¨¡å‹è¨“ç·´å®Œæˆä¸¦å·²å„²å­˜ç‚º model_food.pth\n"
     ]
    }
   ],
   "source": [
    "#  AI ç¾é£Ÿé¡§å•ç³»çµ± + è¨“ç·´æ¨¡å‹ç¨‹å¼ç¢¼ + åœ–ç‰‡é è¦½åŠŸèƒ½\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# è¨­å®šè£ç½®\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# è³‡æ–™èˆ‡æ¨¡å‹è·¯å¾‘\n",
    "food_info_path = \"C:/Users/echo6/Downloads/Food/food_info.csv\"\n",
    "data_path = \"C:/Users/echo6/Downloads/Food/data/food-101-tiny\"\n",
    "model_weights_path = \"model_food.pth\"\n",
    "\n",
    "# åœ–ç‰‡è½‰æ›\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# è¼‰å…¥è³‡æ–™é›†\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(data_path, \"train\"), transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=os.path.join(data_path, \"valid\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# æ¨¡å‹æ¶æ§‹\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# è¼‰å…¥èªªæ˜\n",
    "df = pd.read_csv(food_info_path)\n",
    "food_dict = dict(zip(df['food'], df['description']))\n",
    "class_names = sorted(list(food_dict.keys()))\n",
    "\n",
    "# å»ºç«‹æ¨¡å‹\n",
    "num_classes = len(class_names)\n",
    "model = LeNet5(num_classes).to(device)\n",
    "if os.path.exists(model_weights_path):\n",
    "    model.load_state_dict(torch.load(model_weights_path, map_location=device))\n",
    "    print(\"âœ… æ¨¡å‹å·²æˆåŠŸè¼‰å…¥\")\n",
    "else:\n",
    "    print(\"âš ï¸ å°šæœªè¼‰å…¥æ¨¡å‹æ¬Šé‡ï¼Œè«‹ç¢ºèªæ˜¯å¦å…ˆè¨“ç·´æ¨¡å‹\")\n",
    "model.eval()\n",
    "\n",
    "def analyze_food_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        display(image)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åœ–ç‰‡è®€å–éŒ¯èª¤: {e}\")\n",
    "        return\n",
    "\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        top3 = torch.topk(probs, 3)\n",
    "\n",
    "        print(\"ğŸ“Š é æ¸¬å‰ 3 åï¼š\")\n",
    "        for i in range(3):\n",
    "            idx = top3.indices[0][i].item()\n",
    "            score = top3.values[0][i].item()\n",
    "            print(f\"Top {i+1}: {class_names[idx]}ï¼ˆä¿¡å¿ƒå€¼ï¼š{score:.2%}ï¼‰\")\n",
    "\n",
    "        class_index = top3.indices[0][0].item()\n",
    "        food_name = class_names[class_index]\n",
    "\n",
    "    print(f\"\\nğŸ½ï¸ é æ¸¬é£Ÿç‰©ï¼ˆæœ€å¯èƒ½ï¼‰ï¼š{food_name}\")\n",
    "    print(f\"ğŸ“˜ é£Ÿç‰©èªªæ˜ï¼š{food_dict.get(food_name, 'æŸ¥ç„¡è³‡æ–™')}\")\n",
    "\n",
    "# ğŸ§  è¨“ç·´æ¨¡å‹ï¼ˆå¦‚å°šæœªè¨“ç·´ï¼‰\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# åŸ·è¡Œè¨“ç·´\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    loss, train_acc = train(model, train_loader)\n",
    "    val_acc = validate(model, valid_loader)\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "# å„²å­˜æ¨¡å‹\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "print(\"âœ… æ¨¡å‹è¨“ç·´å®Œæˆä¸¦å·²å„²å­˜ç‚º model_food.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a022dd8-7dca-4225-9797-0215393a9477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
